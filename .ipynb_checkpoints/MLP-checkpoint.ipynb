{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92aa3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348fd9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18b44f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_data = np.array(X_training).T\n",
    "X_train = X_data[1:785]\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "\n",
    "X_train_1 = X_train[:, 0:1000]\n",
    "X_train_1.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a20066ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_train[:, 1].reshape(784,1)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b59fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = (X_train.astype('float32') / 255.0 * 0.99) + 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bcc22ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = X_data[0]\n",
    "Y_targs = np.eye(10)[Y_train]\n",
    "\n",
    "Y_targs = Y_targs.T\n",
    "Y_targs.shape\n",
    "\n",
    "\n",
    "Y_targs_1 = Y_targs[:, 0:1000]\n",
    "Y_targs_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a381a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        \n",
    "        self.input_weights = np.random.randn(self.hidden_nodes, self.input_nodes) / np.sqrt(self.input_nodes)\n",
    "        #self.input_weights = np.random.uniform(-0.02, 0.02, (self.hidden_nodes, self.input_nodes)) / np.sqrt(self.input_nodes)\n",
    "        self.hidden_weights = np.random.rand(self.output_nodes, self.hidden_nodes) / np.sqrt(self.hidden_nodes)\n",
    "        #self.hidden_weights = np.random.uniform(-0.02, 0.02, (self.output_nodes, self.hidden_nodes)) / np.sqrt(self.hidden_nodes)\n",
    "        #self.hidden_bias = np.random.rand(self.output_nodes, 1) - 0.5\n",
    "        #self.input_bias = np.random.rand(self.hidden_nodes, 1) - 0.5\n",
    "        self.hidden_bias = np.zeros((self.output_nodes, 1))\n",
    "        self.input_bias = np.zeros((self.hidden_nodes, 1))\n",
    "         \n",
    "        \n",
    "    def feed_forward(self,X):\n",
    "        \n",
    "        self.Z1 = np.dot(self.input_weights, X) + self.input_bias\n",
    "        #self.A1 = self.sigmoid(self.Z1)\n",
    "        self.A1 = self.LReLU(self.Z1)\n",
    "        self.Z2 = np.dot(self.hidden_weights, self.A1) + self.hidden_bias\n",
    "        out = self.softmax(self.Z2)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return np.where(x >= 0, \n",
    "                    1 / (1 + np.exp(-x)), \n",
    "                    np.exp(x) / (1 + np.exp(x)))\n",
    "    \n",
    "    def softmax(self,Z):\n",
    "        A = np.exp(Z) / sum(np.exp(Z))\n",
    "        return A\n",
    "    \n",
    "    def LReLU(self, x):\n",
    "        return np.maximum(0.01*x, x)\n",
    "        \n",
    "        \n",
    "    def DerivReLU(self, x):\n",
    "        return np.where(x <= 0, 0.01, 1)\n",
    "\n",
    "    def cross_entropy(self, y_true, y_pred):\n",
    "        m = y_true.shape[1]\n",
    "        log_likelihood = -np.sum(np.log(y_pred) * y_true) / m\n",
    "        return log_likelihood\n",
    "        \n",
    "        \n",
    "    def backprop(self, inputs_list, targets_list):\n",
    "        \n",
    "        m = targets_list.size\n",
    "        outs = self.feed_forward(inputs_list)\n",
    "        output_error = outs - targets_list\n",
    "        print(self.cross_entropy(targets_list, outs))\n",
    "        soft_error = outs * (1-outs)\n",
    "        dz2 = output_error * soft_error\n",
    "        dw2 = 1/m * np.dot(dz2, self.A1.T)\n",
    "        db2 = 1/m * dz2\n",
    "        da1 = np.dot(self.hidden_weights.T, dz2)\n",
    "        #dz1 = da1 * self.A1 * (1-self.A1)\n",
    "        dz1 = da1 * self.DerivReLU(self.Z1)\n",
    "        dw1 = 1/m * np.dot(dz1, inputs_list.T)\n",
    "        db1 = 1/m * dz1\n",
    "        \n",
    "        \n",
    "        \n",
    "        return dw1, dw2, db1, db2\n",
    "    \n",
    "    \n",
    "    def get_predictions(self, X2):\n",
    "        return np.argmax(X2, 0)\n",
    "    \n",
    "    \n",
    "    def train(self, inputs_list, targets_list, epochs=100, lr=0.001):\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            #print(\"Iteration: \" + str(i))\n",
    "            \n",
    "            input_weights, hidden_weights, input_bias, hidden_bias  = self.backprop(inputs_list, targets_list)\n",
    "            self.input_weights = self.input_weights - (lr*input_weights)\n",
    "            self.hidden_weights = self.hidden_weights - (lr*hidden_weights)\n",
    "            self.input_bias = self.input_bias - (lr*input_bias)\n",
    "            self.hidden_bias = self.hidden_bias - (lr*hidden_bias)\n",
    "            \n",
    "        outputs = self.feed_forward(inputs_list)\n",
    "            \n",
    "        return self.get_predictions(outputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3486f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = MLP(784, 100, 10)\n",
    "Y_targs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e262e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.808138732162252\n",
      "11.211442099358255\n",
      "5.436665930955738\n",
      "3.4183354462381104\n",
      "2.831648311326374\n",
      "2.568347667903162\n",
      "2.4045613031081414\n",
      "2.284389255264538\n",
      "2.1922402016531377\n",
      "2.113280385869064\n",
      "2.0410807016051393\n",
      "1.9719578102403728\n",
      "1.906721164702037\n",
      "1.8433650639735397\n",
      "1.788217884877511\n",
      "1.7388636253238583\n",
      "1.693182750591873\n",
      "1.6508875936916525\n",
      "1.6110691335957117\n",
      "1.573386670631497\n",
      "1.5379577262667428\n",
      "1.503951472692241\n",
      "1.4714521392260838\n",
      "1.4399158684785676\n",
      "1.409837829095145\n",
      "1.380392447402293\n",
      "1.352902589661839\n",
      "1.326078964053846\n",
      "1.2997409340732307\n",
      "1.273430063407064\n",
      "1.247434145156806\n",
      "1.2225144205106564\n",
      "1.1968050624764601\n",
      "1.1723722091287647\n",
      "1.1469806633474025\n",
      "1.1213089476224554\n",
      "1.0926199537041317\n",
      "1.064733916639288\n",
      "1.0339582690397449\n",
      "1.0012332031200042\n",
      "0.9689807429770739\n",
      "0.9392332726605287\n",
      "0.911063685092949\n",
      "0.8861578715459659\n",
      "0.8624994556958786\n",
      "0.8400651901406189\n",
      "0.818440380613977\n",
      "0.7978153850789449\n",
      "0.778226344540307\n",
      "0.7608093200882616\n",
      "0.7433098897006509\n",
      "0.7283183185086385\n",
      "0.7120629616612484\n",
      "0.6974858758077098\n",
      "0.6827959356883971\n",
      "0.6689276627171898\n",
      "0.6555028730830511\n",
      "0.6426242513248248\n",
      "0.629990794931758\n",
      "0.6177460912081111\n",
      "0.6061202413681542\n",
      "0.5948219360115792\n",
      "0.5834808040069939\n",
      "0.573086497008947\n",
      "0.5627474708559155\n",
      "0.552720266553111\n",
      "0.5425106930138824\n",
      "0.5332131624011143\n",
      "0.5234058394271796\n",
      "0.5141645042812725\n",
      "0.5050754674348602\n",
      "0.49641737264282493\n",
      "0.488315929785942\n",
      "0.48013436779802526\n",
      "0.47226599569434313\n",
      "0.46468736770366825\n",
      "0.4574488383421305\n",
      "0.45042280924767014\n",
      "0.4440068466349572\n",
      "0.43760311248854145\n",
      "0.43112702214838217\n",
      "0.4245808419294892\n",
      "0.41853332308824565\n",
      "0.41226433903183785\n",
      "0.40662010240661395\n",
      "0.4009944722316959\n",
      "0.395479319614683\n",
      "0.3898306283533343\n",
      "0.3841895880275937\n",
      "0.37937899668886305\n",
      "0.37436498403742813\n",
      "0.3693558985592016\n",
      "0.36480935201542947\n",
      "0.3600154845774132\n",
      "0.35546076966171664\n",
      "0.3513162786892939\n",
      "0.3466623486059469\n",
      "0.34233208787756075\n",
      "0.3381847655649675\n",
      "0.3339764821016112\n",
      "0.3299687634268645\n",
      "0.32584418190755154\n",
      "0.32194413382643744\n",
      "0.3180975414103109\n",
      "0.314204240636644\n",
      "0.31008230691034566\n",
      "0.30636050168728146\n",
      "0.3024216447213444\n",
      "0.2986648392206996\n",
      "0.29488616131245865\n",
      "0.2915190628941136\n",
      "0.28788344734987675\n",
      "0.28434881987491833\n",
      "0.2807861112916509\n",
      "0.27737792566013253\n",
      "0.2740028049400244\n",
      "0.27098060431969606\n",
      "0.2676831339584047\n",
      "0.2645009714711272\n",
      "0.2611183030452456\n",
      "0.25776389430890817\n",
      "0.254555450749035\n",
      "0.25125890454658445\n",
      "0.2479327948526705\n",
      "0.24478946912612068\n",
      "0.24150143515088368\n",
      "0.23841398201277206\n",
      "0.23558865266649193\n",
      "0.232608259725283\n",
      "0.2297181675268649\n",
      "0.22712632965146695\n",
      "0.22461225043931693\n",
      "0.2219736113175694\n",
      "0.21937162856058826\n",
      "0.21708826217980493\n",
      "0.2149224182653907\n",
      "0.21238126358045226\n",
      "0.21049222416535893\n",
      "0.20804910044114905\n",
      "0.20601789290952394\n",
      "0.20395359105365343\n",
      "0.201853327278297\n",
      "0.19969029298328705\n",
      "0.1977337318870079\n",
      "0.19573980518436776\n",
      "0.19389099605752216\n",
      "0.19207173702198646\n",
      "0.19021562531065037\n",
      "0.18886866716981832\n",
      "0.18719040232915837\n",
      "0.1856251395125733\n",
      "0.18409176217525106\n",
      "0.18262374892425362\n",
      "0.1809982843614374\n",
      "0.1795373757647112\n",
      "0.17806747625346808\n",
      "0.17651453053353688\n",
      "0.174989894020953\n",
      "0.1736762509584825\n",
      "0.17183153978711393\n",
      "0.17051746881468857\n",
      "0.16876599813574336\n",
      "0.16760241638659698\n",
      "0.16574443680050677\n",
      "0.1647749486519598\n",
      "0.16294354314050513\n",
      "0.16176933960496684\n",
      "0.16024383495713557\n",
      "0.15896629801701573\n",
      "0.15755364203402164\n",
      "0.15600072562719436\n",
      "0.15477297627406242\n",
      "0.15311905509051538\n",
      "0.1520796145147557\n",
      "0.1502325489141444\n",
      "0.1489768233392823\n",
      "0.14796129400963173\n",
      "0.1463813005944441\n",
      "0.14512829377878103\n",
      "0.14397890670683292\n",
      "0.14257305855668748\n",
      "0.14092450626189798\n",
      "0.14049015476012178\n",
      "0.13853621472757915\n",
      "0.13795150692450656\n",
      "0.1359192756397401\n",
      "0.13523454061805953\n",
      "0.1335412013538858\n",
      "0.13263754520635365\n",
      "0.1311961370600932\n",
      "0.1302303737825822\n",
      "0.12890112713754073\n",
      "0.12828863501392854\n",
      "0.12677620002942588\n",
      "0.12598675098874082\n",
      "0.12491431639575835\n",
      "0.12406952991769055\n",
      "0.12299391712405665\n",
      "0.12231470656513536\n",
      "0.12129034941366093\n",
      "0.12097067134800264\n",
      "0.11969034054129947\n",
      "0.11888434637835196\n",
      "0.1185294868759213\n",
      "0.11766489077250193\n",
      "0.11678288098556172\n",
      "0.11638422913222007\n",
      "0.11562181662331664\n",
      "0.11497485369770431\n",
      "0.11468732265168052\n",
      "0.11387668362246244\n",
      "0.11343882848830418\n",
      "0.1129972988285159\n",
      "0.11224773031136019\n",
      "0.11167505614000577\n",
      "0.11147861869264579\n",
      "0.11053384032036201\n",
      "0.11049272892870105\n",
      "0.10938950016823569\n",
      "0.10885163660129467\n",
      "0.1079517578613811\n",
      "0.10743406458725042\n",
      "0.106676247596301\n",
      "0.10605682923199604\n",
      "0.10551862013154628\n",
      "0.10464619104322696\n",
      "0.10425923852357602\n",
      "0.10320856549266011\n",
      "0.10304167879312331\n",
      "0.10188040384625341\n",
      "0.1018367558278826\n",
      "0.10095832977869773\n",
      "0.10063652756453795\n",
      "0.09959909342720608\n",
      "0.09952149539963055\n",
      "0.0985923279371254\n",
      "0.09849900704765026\n",
      "0.09758746437176628\n",
      "0.09748826093164001\n",
      "0.0966981698650188\n",
      "0.09649704154677949\n",
      "0.09597405055811327\n",
      "0.09586864871434607\n",
      "0.09528315785481153\n",
      "0.09512333965478072\n",
      "0.09455014121274823\n",
      "0.09454425552824484\n",
      "0.09384728458170569\n",
      "0.09374312101075437\n",
      "0.09299901504992165\n",
      "0.09326598702930743\n",
      "0.09251298685833297\n",
      "0.09263626072517712\n",
      "0.09196024720529211\n",
      "0.09289100010377356\n",
      "0.09221946731952789\n",
      "0.09397289573205735\n",
      "0.09441103720131017\n",
      "0.09967414227040605\n",
      "0.11014397508397974\n",
      "0.12839599200213617\n",
      "0.15868429177257576\n",
      "0.11488120110599188\n",
      "0.09122210024564871\n",
      "0.08465781024329226\n",
      "0.0792363448046479\n",
      "0.07957342472556839\n",
      "0.07964539955382222\n",
      "0.07973289581239054\n",
      "0.07982822595343883\n",
      "0.07978503487452784\n",
      "0.07995374670656659\n",
      "0.07989966377156925\n",
      "0.07988130385463048\n",
      "0.07986789064287496\n",
      "0.07966520381064772\n",
      "0.07963531411045016\n",
      "0.07955064049853898\n",
      "0.07942593086794669\n",
      "0.07920330834926922\n",
      "0.07918782713360015\n",
      "0.07915438230934617\n",
      "0.07888847580389637\n",
      "0.07904267017005866\n",
      "0.0789072031364469\n",
      "0.07884070847555728\n",
      "0.07883215264818011\n",
      "0.07907549105971773\n",
      "0.07880239595624967\n",
      "0.07925160286282475\n",
      "0.07875533370900684\n",
      "0.08013061443444255\n",
      "0.07904588251629663\n",
      "0.08240860309689234\n",
      "0.0815427335842754\n",
      "0.09629354239986898\n",
      "0.14694928571149746\n",
      "0.20418666388491286\n",
      "0.24008035188886107\n",
      "0.09885235003414518\n",
      "0.06997548444779282\n",
      "0.06859025207537006\n",
      "0.06555393928745351\n",
      "0.06547297849106075\n",
      "0.0653950138071045\n",
      "0.06540153218659003\n",
      "0.0654823121462669\n",
      "0.06555557731006585\n",
      "0.06568383785194727\n",
      "0.06581162823134669\n",
      "0.06585636056333147\n",
      "0.06596743092534547\n",
      "0.06607486649155254\n",
      "0.06617080536770643\n",
      "0.06625550633244\n",
      "0.06637311548594126\n",
      "0.06653776934959008\n",
      "0.06661388470585763\n",
      "0.0666975291095619\n",
      "0.06676428749306673\n",
      "0.06687506047529486\n",
      "0.06703619290504628\n",
      "0.06705503548961603\n",
      "0.0671639423317824\n",
      "0.06715805566721346\n",
      "0.06723879537144628\n",
      "0.06730215626251015\n",
      "0.06730514157955503\n",
      "0.06729798418553185\n",
      "0.06724576860113975\n",
      "0.06717182871508129\n",
      "0.06726409965330579\n",
      "0.0670976045103229\n",
      "0.06708904518184451\n",
      "0.06699338834426195\n",
      "0.06684832419288338\n",
      "0.0668817700847516\n",
      "0.06670364899256472\n",
      "0.06660704533727807\n",
      "0.0665604162051583\n",
      "0.06643898404089471\n",
      "0.06646323140822494\n",
      "0.06628184269852441\n",
      "0.06624133215435499\n",
      "0.06615811585804289\n",
      "0.06599060216023891\n",
      "0.06579799458378056\n",
      "0.06570575947521994\n",
      "0.06556354899545479\n",
      "0.0654731558198473\n",
      "0.06528579918172588\n",
      "0.06513741521292633\n",
      "0.06501228388124629\n",
      "0.06489432450284384\n",
      "0.06479612135005226\n",
      "0.0646929398167533\n",
      "0.06467107465922793\n",
      "0.06458815819132581\n",
      "0.06462721911984733\n",
      "0.06450527172825335\n",
      "0.06485525421875218\n",
      "0.06473322588485707\n",
      "0.06719963102442103\n",
      "0.07006900203745858\n",
      "0.11222848785153032\n",
      "0.12537039740196407\n",
      "0.3260071801879879\n",
      "0.3978298654227491\n",
      "0.14687096975805805\n",
      "0.05955812166739922\n",
      "0.05378489368435817\n",
      "0.052674546370331636\n",
      "0.05190928634951779\n",
      "0.05128514186657662\n",
      "0.050795429508701584\n",
      "0.05043303363182057\n",
      "0.050162076399960114\n",
      "0.04996030197894974\n",
      "0.04980749034731298\n",
      "0.0496865631616449\n",
      "0.04958785269888904\n",
      "0.04950629988147425\n",
      "0.04943779569204046\n",
      "0.04938018096979523\n",
      "0.049330583628727456\n",
      "0.04928621091183556\n",
      "0.04924963088256879\n",
      "0.04918719499896433\n",
      "0.049178416578283646\n",
      "0.04912307488487593\n",
      "0.04907805531774594\n",
      "0.04908320037456582\n",
      "0.04903250958275998\n",
      "0.04898685078110464\n",
      "0.048955598935669496\n",
      "0.04897080057101534\n",
      "0.04891163446817003\n",
      "0.04888048149021314\n",
      "0.0488700648788913\n",
      "0.048813314735404165\n",
      "0.04878544664647093\n",
      "0.04873803044275914\n",
      "0.048738168149201476\n",
      "0.04869483950347563\n",
      "0.0486572919113903\n",
      "0.04864252530712818\n",
      "0.04860535274792292\n",
      "0.04862825835415949\n",
      "0.04858197365518014\n",
      "0.04854388962554206\n",
      "0.04852875459033274\n",
      "0.04849022934161978\n",
      "0.04850809096072464\n",
      "0.048464627204014975\n",
      "0.04841158367068871\n",
      "0.04834443710867599\n",
      "0.048295839070303055\n",
      "0.04824891952080968\n",
      "0.04819832113802212\n",
      "0.04814983161749772\n",
      "0.04809527320724641\n",
      "0.04804208747001995\n",
      "0.047997845691895615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04796776114289886\n",
      "0.0479489056433652\n",
      "0.04794209804349635\n",
      "0.04794690874713322\n",
      "0.047966977457023184\n",
      "0.04799089265577202\n",
      "0.04802010248570167\n",
      "0.048057855909607185\n",
      "0.048095335848087846\n",
      "0.04813200771777113\n",
      "0.04816035180710835\n",
      "0.04819464315973637\n",
      "0.04823331551021523\n",
      "0.048275861481823695\n",
      "0.04832651976542349\n",
      "0.04837589498519573\n",
      "0.04842769846362014\n",
      "0.04847977712205936\n",
      "0.04852591243680806\n",
      "0.04858130602101787\n",
      "0.048628865721498694\n",
      "0.048659973269306794\n",
      "0.04868965743973463\n",
      "0.048718840605586906\n",
      "0.048743341092920715\n",
      "0.048766165110754385\n",
      "0.04880134147957018\n",
      "0.0488256976466146\n",
      "0.048852935397448324\n",
      "0.04888170243904951\n",
      "0.048919728999133875\n",
      "0.048963898754307504\n",
      "0.049005619246810864\n",
      "0.049046989357803786\n",
      "0.049092532474085085\n",
      "0.04914488693127948\n",
      "0.04917845711292415\n",
      "0.04921420295420088\n",
      "0.049248680998231875\n",
      "0.04927942020002064\n",
      "0.049309804636394006\n",
      "0.04933145904465433\n",
      "0.04935068879226058\n",
      "0.04937662463071373\n",
      "0.04940375261107693\n",
      "0.04941894045313629\n",
      "0.04944350472011716\n",
      "0.04947934431938633\n",
      "0.04949517410111347\n",
      "0.04951866841253852\n",
      "0.04952378038682987\n",
      "0.04955189227130045\n",
      "0.049571021160214154\n",
      "0.049603261537721786\n",
      "0.04963922842081628\n",
      "0.04968166108838188\n",
      "0.04973165494644064\n",
      "0.04977311895316814\n",
      "0.04982521004144236\n",
      "0.049870181270165924\n",
      "0.04991905000761391\n",
      "0.04996527167792475\n",
      "0.050017226544877606\n",
      "0.050060748885886734\n",
      "0.050116196229842716\n",
      "0.05016327044003206\n",
      "0.050211148683321855\n",
      "0.05025692982015903\n",
      "0.05030263386350559\n",
      "0.050363296114042055\n",
      "0.050403640602820314\n",
      "0.05048910007936296\n",
      "0.05052117379303089\n",
      "0.050674105442449026\n",
      "0.05073825758591594\n",
      "0.051186361837505204\n",
      "0.051932238660653975\n"
     ]
    }
   ],
   "source": [
    "b = c.train(X_train_1, Y_targs_1, 500, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6e9231c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 4, 0, 0, 7, 3, 5, 3, 8, 9, 1, 3, 3, 1, 2, 0, 7, 5, 8, 6,\n",
       "       2, 0, 2, 3, 6, 9, 9, 7, 8, 9, 4, 9, 2, 1, 3, 1, 1, 4, 9, 1, 4, 4,\n",
       "       2, 6, 3, 7, 7, 4, 7, 5, 1, 9, 0, 2, 2, 3, 9, 1, 1, 1, 5, 0, 6, 3,\n",
       "       4, 8, 1, 0, 3, 9, 6, 2, 6, 4, 7, 1, 4, 1, 5, 4, 8, 9, 2, 9, 9, 8,\n",
       "       9, 6, 3, 6, 4, 6, 2, 9, 1, 2, 0, 5, 9, 2, 7, 7, 2, 8, 8, 5, 0, 6,\n",
       "       0, 0, 2, 9, 0, 4, 7, 7, 1, 5, 7, 9, 4, 6, 1, 5, 7, 6, 5, 0, 4, 8,\n",
       "       7, 6, 1, 8, 7, 3, 7, 3, 1, 0, 3, 4, 5, 4, 0, 5, 4, 0, 3, 5, 1, 0,\n",
       "       8, 3, 7, 0, 9, 6, 6, 9, 5, 4, 6, 9, 3, 5, 4, 2, 9, 8, 7, 7, 5, 8,\n",
       "       8, 8, 2, 6, 9, 3, 1, 0, 4, 1, 5, 9, 0, 6, 2, 1, 3, 0, 6, 0, 0, 8,\n",
       "       3, 2, 0, 0, 6, 0, 0, 4, 7, 2, 7, 1, 9, 9, 3, 9, 8, 4, 6, 6, 5, 3,\n",
       "       8, 1, 8, 7, 1, 3, 7, 6, 3, 6, 3, 6, 3, 2, 3, 2, 2, 7, 9, 2, 2, 2,\n",
       "       7, 5, 5, 8, 8, 2, 0, 1, 4, 0, 6, 3, 7, 1, 1, 1, 4, 7, 0, 2, 9, 2,\n",
       "       0, 5, 6, 0, 8, 9, 6, 2, 0, 0, 7, 2, 0, 4, 2, 0, 9, 1, 6, 9, 3, 0,\n",
       "       0, 2, 0, 6, 8, 4, 0, 7, 2, 1, 9, 5, 2, 4, 8, 5, 2, 9, 7, 9, 2, 9,\n",
       "       7, 4, 9, 3, 2, 7, 3, 6, 3, 6, 8, 8, 3, 7, 0, 9, 2, 7, 9, 0, 5, 4,\n",
       "       5, 8, 4, 3, 3, 1, 7, 8, 9, 7, 6, 2, 1, 7, 0, 5, 6, 5, 2, 9, 5, 4,\n",
       "       6, 2, 2, 2, 9, 0, 7, 7, 2, 2, 6, 3, 4, 2, 0, 5, 9, 6, 2, 1, 9, 0,\n",
       "       6, 0, 4, 8, 4, 3, 1, 5, 4, 2, 9, 5, 7, 3, 1, 5, 4, 5, 3, 7, 3, 8,\n",
       "       6, 2, 4, 6, 1, 1, 4, 0, 0, 5, 8, 6, 7, 4, 2, 8, 0, 2, 5, 4, 8, 3,\n",
       "       0, 6, 4, 8, 6, 4, 1, 8, 1, 5, 4, 9, 4, 3, 2, 0, 5, 0, 7, 9, 2, 9,\n",
       "       8, 9, 6, 5, 2, 4, 4, 6, 4, 8, 4, 1, 7, 5, 8, 9, 5, 9, 3, 2, 5, 8,\n",
       "       2, 2, 7, 2, 8, 4, 1, 9, 3, 6, 0, 2, 2, 9, 1, 2, 7, 2, 1, 3, 4, 9,\n",
       "       1, 8, 0, 2, 2, 3, 4, 1, 3, 7, 4, 1, 4, 1, 5, 9, 6, 9, 0, 5, 7, 6,\n",
       "       8, 2, 0, 7, 3, 5, 8, 2, 8, 2, 4, 8, 5, 8, 9, 7, 1, 2, 4, 5, 5, 1,\n",
       "       8, 1, 4, 4, 6, 5, 8, 9, 2, 3, 0, 5, 1, 4, 0, 5, 1, 2, 9, 2, 4, 1,\n",
       "       6, 8, 0, 4, 9, 0, 0, 5, 9, 2, 3, 5, 9, 4, 4, 3, 9, 2, 3, 5, 6, 5,\n",
       "       2, 7, 2, 4, 2, 4, 7, 2, 5, 3, 9, 6, 1, 0, 7, 5, 4, 5, 1, 6, 9, 7,\n",
       "       1, 6, 3, 3, 1, 2, 2, 0, 5, 0, 6, 8, 3, 6, 7, 7, 3, 8, 1, 7, 9, 3,\n",
       "       9, 2, 8, 3, 7, 4, 1, 2, 3, 6, 5, 0, 1, 8, 6, 9, 2, 1, 6, 0, 2, 8,\n",
       "       0, 8, 8, 9, 1, 2, 2, 1, 4, 8, 1, 4, 4, 5, 1, 8, 7, 7, 9, 7, 0, 6,\n",
       "       9, 4, 5, 6, 2, 5, 7, 4, 7, 2, 3, 0, 8, 4, 8, 0, 0, 9, 7, 8, 9, 8,\n",
       "       2, 1, 6, 5, 5, 1, 1, 9, 7, 7, 8, 6, 4, 7, 5, 3, 1, 6, 4, 5, 7, 4,\n",
       "       1, 8, 3, 5, 1, 7, 1, 1, 8, 6, 4, 3, 8, 3, 1, 2, 8, 9, 0, 9, 1, 2,\n",
       "       3, 3, 0, 3, 0, 2, 0, 3, 3, 8, 3, 5, 7, 0, 5, 9, 0, 5, 9, 1, 5, 1,\n",
       "       1, 2, 6, 5, 5, 4, 5, 1, 6, 0, 2, 2, 8, 0, 7, 1, 0, 8, 5, 6, 3, 2,\n",
       "       9, 4, 3, 6, 0, 3, 4, 1, 5, 9, 3, 0, 5, 0, 6, 2, 7, 6, 6, 6, 9, 6,\n",
       "       7, 8, 2, 0, 6, 0, 8, 9, 5, 3, 6, 7, 4, 3, 9, 7, 2, 0, 4, 7, 2, 2,\n",
       "       8, 2, 7, 0, 4, 0, 5, 2, 8, 7, 7, 9, 1, 4, 0, 1, 1, 2, 3, 6, 2, 0,\n",
       "       6, 6, 1, 9, 4, 5, 2, 7, 7, 8, 9, 5, 8, 3, 8, 5, 6, 2, 0, 9, 7, 1,\n",
       "       8, 2, 6, 9, 8, 4, 9, 4, 1, 3, 8, 4, 0, 7, 7, 3, 7, 6, 6, 8, 8, 2,\n",
       "       7, 0, 4, 3, 7, 7, 0, 8, 4, 7, 4, 0, 6, 9, 8, 6, 0, 1, 6, 4, 5, 2,\n",
       "       7, 3, 6, 2, 2, 9, 2, 7, 4, 8, 7, 2, 9, 5, 3, 4, 8, 0, 4, 4, 6, 5,\n",
       "       6, 1, 2, 2, 8, 4, 5, 7, 8, 0, 6, 8, 9, 1, 7, 7, 2, 6, 3, 9, 9, 1,\n",
       "       0, 4, 2, 5, 4, 4, 9, 2, 6, 7, 2, 8, 3, 3, 2, 7, 0, 4, 7, 0, 7, 7,\n",
       "       8, 1, 7, 3, 7, 8, 0, 1, 0, 2, 9, 7, 6, 2, 2, 6, 9, 0, 6, 8, 8, 9,\n",
       "       6, 3, 5, 0, 2, 2, 5, 9, 6, 4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b54c588a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(b == Y_train[:1000])*100 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80055184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_targs_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e876528",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92add51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_targs = np.eye(10)[Y_train]\n",
    "Y_targs.shape\n",
    "\n",
    "Y_train[:1000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bfa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_targs_1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81569803",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([0, 1, 4, 9, 16, 25], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78246ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.(np.random.uniform(-0.02, 0.02, (3, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8665e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = X_train_1[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "74011ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = current_image.reshape((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "46bc2e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(current_image, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7d47c124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0de55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
